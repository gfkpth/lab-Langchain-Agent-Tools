{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ede2e1",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This notebook aims to experiment with giving an agent access to two different databases (one sourced from my my personal website, one sourced from my published work, i.e. extracted from pdfs).\n",
    "\n",
    "*Currently incomplete.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2532490e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: langchain[openai] in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (0.3.25)\n",
      "Collecting langchain[openai]\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66 (from langchain[openai])\n",
      "  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langchain[openai]) (0.3.8)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langchain[openai]) (0.3.45)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langchain[openai]) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langchain[openai]) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langchain[openai]) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langchain[openai]) (6.0.2)\n",
      "Requirement already satisfied: langchain-openai in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langchain[openai]) (0.3.24)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[openai]) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[openai]) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[openai]) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain[openai]) (4.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain[openai]) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain[openai]) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain[openai]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain[openai]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain[openai]) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain[openai]) (2025.6.15)\n",
      "Requirement already satisfied: greenlet>=1 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain[openai]) (3.2.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain[openai]) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain[openai]) (3.10.18)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain[openai]) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain[openai]) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[openai]) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[openai]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[openai]) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[openai]) (1.3.1)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langchain-openai->langchain[openai]) (1.88.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from langchain-openai->langchain[openai]) (0.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai->langchain[openai]) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai->langchain[openai]) (0.10.0)\n",
      "Requirement already satisfied: tqdm>4 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.86.0->langchain-openai->langchain[openai]) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /home/georg/anaconda3/envs/nlp.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai->langchain[openai]) (2024.11.6)\n",
      "Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n",
      "Installing collected packages: langchain-core, langchain\n",
      "\u001b[2K  Attempting uninstall: langchain-core\n",
      "\u001b[2K    Found existing installation: langchain-core 0.3.65\n",
      "\u001b[2K    Uninstalling langchain-core-0.3.65:\n",
      "\u001b[2K      Successfully uninstalled langchain-core-0.3.65\n",
      "\u001b[2K  Attempting uninstall: langchain━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [langchain-core]\n",
      "\u001b[2K    Found existing installation: langchain 0.3.25\u001b[32m0/2\u001b[0m [langchain-core]\n",
      "\u001b[2K    Uninstalling langchain-0.3.25:━━━━━━━━━━\u001b[0m \u001b[32m0/2\u001b[0m [langchain-core]\n",
      "\u001b[2K      Successfully uninstalled langchain-0.3.25m \u001b[32m0/2\u001b[0m [langchain-core]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [langchain]/2\u001b[0m [langchain]\n",
      "\u001b[1A\u001b[2KSuccessfully installed langchain-0.3.26 langchain-core-0.3.66\n"
     ]
    }
   ],
   "source": [
    "#pip install -U langgraph langsmith\n",
    "#!pip install -U \"langchain[openai]\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba94e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import glob\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f8a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HSS2016_UnagreementItalian_RSS_fixed.pdf',\n",
       " 'HoehnSilvestriSquillaci2016.pdf',\n",
       " 'Hoehn2011_wroclaw_basqueko.pdf',\n",
       " 'Hoehn2013_langborders_FoI2013_nomov.pdf',\n",
       " 'languagePower_draft.pdf',\n",
       " 'basque_locative_recos.pdf',\n",
       " 'Hoehn2009_rusger_participles_handout.pdf',\n",
       " 'Hoehn2014_console21.pdf',\n",
       " 'handout_unagreement_ISTAL.pdf',\n",
       " 'Hoehn2012_MRes_greekunagreement.pdf',\n",
       " 'Hoehn2012_The-Licensing-of-Adnominal-PPs-The-Case-of-Basque-ko.pdf',\n",
       " 'Hoehn2017_Nonpossessive person in the nominal domain.pdf',\n",
       " 'Hoehn2015_Demonstratives and personal pronouns.pdf',\n",
       " 'Hoehn2014_Semantics of unagreement.pdf',\n",
       " 'hoehn_unagreement_NLLT.pdf',\n",
       " 'Hoehn2018_draft_ElicitNomPers.pdf',\n",
       " 'MGDLT10_Greko and Greek PPs_poster.pdf',\n",
       " '07_Bachelor',\n",
       " '15_Demonstratives+PersonalPron_CWPL',\n",
       " '15_ItalianUnagreement',\n",
       " 'Hoehn2012_The-Licensing-of-Adnominal-PPs-The-Case-of-Basque-ko.pdf',\n",
       " 'HoehnSilvestriSquillaci2017_Greek and Romance unagreement in Calabria.pdf',\n",
       " 'Hoehn2020_The third person gap in adnominal pronoun constructions.pdf',\n",
       " 'Hoehn2016_Unagreement is an illusion_author.pdf',\n",
       " 'Hoehn2014_Basque_locative_Console21.pdf',\n",
       " 'Hoehn2022_Preposition Allomorphy in Calabrian Greek (Greko) and Std Modern Greek and Its Theoretical implications.pdf',\n",
       " 'HoehnSilvestriSquillaci2016_Unagreement between Italian and southern Italian dialects.pdf',\n",
       " 'Hoehn2015_Unagreement is an illusion.pdf',\n",
       " 'Hoehn2021_Towards a consistent annotation of nominal person in UD.pdf',\n",
       " 'Hoehn2015_Demonstratives and personal pronouns.pdf',\n",
       " 'Hoehn2014_Semantics of unagreement.pdf',\n",
       " 'Höhn2014_Semantics of unagreement.pdf',\n",
       " 'Hoehn2024_A word order typology of adnominal person.pdf',\n",
       " 'Hoehn_2018_draft_Eliciting data on (ad)nominal person.pdf',\n",
       " 'HoehnHien2025_Prenominal a and determiners in three MabiaGur languages.pdf']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_folders = [\"/home/georg/tools/webbing/morelight-md-version/files/papers\",\n",
    "                \"/home/georg/academia/Produziertes/papers\"\n",
    "]\n",
    "files = [f for folder in pdf_folders for f in os.listdir(folder) if os.path.isfile(f) and f.endswith('.pdf')]\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bbc1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify all pdfs in folder\n",
    "pdf_folders = [\"/home/georg/tools/webbing/morelight-md-version/files/papers\",\n",
    "                \"/home/georg/academia/Produziertes/papers\"\n",
    "]\n",
    "files = [f for folder in pdf_folders for f in os.listdir(folder) if os.path.isfile(f) and f.endswith('.pdf')]\n",
    "\n",
    "\n",
    "# function for loading, splitting and chunking pdfs\n",
    "\n",
    "def load_pdf(path,chunk_size=1000,chunk_overlap=200):\n",
    "    loader = PyPDFLoader(path)\n",
    "    pages = loader.load_and_split()\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap\n",
    "    )   \n",
    "    chunks = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d5676f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Override attn_implementation='sdpa' to 'eager' as use_memory_efficient_attention='true'\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# from langchain.embeddings.base import Embeddings\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# from typing import List\n",
    "\n",
    "# class CustomEmbeddings(Embeddings):\n",
    "#     def __init__(self, model_name: str):\n",
    "#         self.model = SentenceTransformer(model_name)\n",
    "\n",
    "#     def embed_documents(self, documents: List[str]) -> List[List[float]]:\n",
    "#         return [self.model.encode(d).tolist() for d in documents]\n",
    "\n",
    "#     def embed_query(self, query: str) -> List[float]:\n",
    "#         return self.model.encode([query])[0].tolist()\n",
    "    \n",
    "    \n",
    "#embedder = HuggingFaceEmbeddings(model_name=\"Snowflake/snowflake-arctic-embed-m-v2.0\")\n",
    "# embedder=\"Snowflake/snowflake-arctic-embed-m-v2.0\"\n",
    "# embeddingsSN = SentenceTransformer(embedder)\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = 'Snowflake/snowflake-arctic-embed-m-v2.0'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "embedder = AutoModel.from_pretrained(model_name, add_pooling_layer=False, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "720c9b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84fef9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "import tiktoken\n",
    "from IPython.display import Markdown, display\n",
    "from  dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = init_chat_model(\"openai:gpt-40-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bebcc83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f22b5d63200>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b6b3682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x7f22b5d63200>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c70d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2b547d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9f34a62",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_tavily'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_tavily\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TavilySearch\n\u001b[1;32m      3\u001b[0m tool \u001b[38;5;241m=\u001b[39m TavilySearch(max_results\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m      4\u001b[0m tools \u001b[38;5;241m=\u001b[39m [tool]\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_tavily'"
     ]
    }
   ],
   "source": [
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "\n",
    "\n",
    "# Safe Tavily wrapper\n",
    "def safe_search(query: str) -> str:\n",
    "    result = tavily_search.run(query)\n",
    "\n",
    "    # Ensure result is a string — Tavily returns dict with 'snippets' sometimes\n",
    "    if isinstance(result, dict):\n",
    "        result_text = result.get(\"content\", \"\") or str(result)\n",
    "    else:\n",
    "        result_text = str(result)\n",
    "\n",
    "    tokens = encoding.encode(result_text)\n",
    "    trimmed = encoding.decode(tokens[:1800])  # leave room for GPT-4 response\n",
    "    return trimmed\n",
    "\n",
    "\n",
    "# LangChain tool\n",
    "tools = [\n",
    "    Tool(name=\"TavilySafeSearch\", func=safe_search, description=\"Web search tool\")]\n",
    "\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "agent = create_react_agent(\n",
    "    llm,\n",
    "    tools=tools,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa08dc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Modification: tell the LLM which tools it can call\n",
    "# highlight-next-line\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1c7424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c94ceb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # should be True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
