{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41222d77",
   "metadata": {},
   "source": [
    "# LAB: Practice with Tavily + LangChain Agents\n",
    "\n",
    "### Objective\n",
    "Reinforce your understanding of LangChain agents integrated with Tavily for real-time web search by solving two open-ended tasks. You'll:\n",
    "- Load and configure a LangChain agent with Tavily\n",
    "- Build effective prompts\n",
    "- Generate structured, useful outputs from real-time data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baadf072",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cafe37d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.agents import initialize_agent, AgentType, Tool\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "import tiktoken\n",
    "from IPython.display import Markdown, display\n",
    "from  dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from langchain.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "load_dotenv()\n",
    "tavily_search = TavilySearchResults()\n",
    "\n",
    "# LLM + Encoding\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0,max_tokens=2000)\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")\n",
    "\n",
    "# Safe Tavily wrapper\n",
    "def safe_search(query: str) -> str:\n",
    "    result = tavily_search.run(query)\n",
    "\n",
    "    # Ensure result is a string — Tavily returns dict with 'snippets' sometimes\n",
    "    if isinstance(result, dict):\n",
    "        result_text = result.get(\"content\", \"\") or str(result)\n",
    "    else:\n",
    "        result_text = str(result)\n",
    "\n",
    "    tokens = encoding.encode(result_text)\n",
    "    trimmed = encoding.decode(tokens[:1800])  # leave room for GPT-4 response\n",
    "    return trimmed\n",
    "\n",
    "\n",
    "# LangChain tool\n",
    "tools = [Tool(name=\"TavilySafeSearch\", func=safe_search, description=\"Web search tool\")]\n",
    "agent = initialize_agent(tools=tools, llm=llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5089593a",
   "metadata": {},
   "source": [
    "### Exercise 1: AI in Healthcare\n",
    "\n",
    "Goal: Investigate and summarize the latest advancements in generative AI applied to healthcare in 2025.\n",
    "\n",
    "- Design a prompt that asks the agent to retrieve the most recent updates.\n",
    "- Ensure the agent outputs a structured response in Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f882ac3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to search for the latest advances in applications of generative AI in healthcare in 2025. I will use the TavilySafeSearch tool to find this information.\n",
      "Action: TavilySafeSearch\n",
      "Action Input: Latest advances in applications of generative AI in healthcare in 2025.\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'Generative AI in Healthcare: Use Cases, Benefits, and Challenges', 'url': 'https://www.johnsnowlabs.com/generative-ai-healthcare/', 'content': 'However, generative AI trends 2025 indicate a shift toward multimodal models capable of analyzing and generating text, images, genomics data, and even real-time patient vitals simultaneously . This advancement will significantly improve diagnostics, clinical decision support, and medical imaging analysis.', 'score': 0.9301101}, {'title': 'Top AI Agents Use case for Healthcare in 2025 - Upskillist', 'url': 'https://www.upskillist.com/blog/top-ai-agents-use-case-for-healthcare-in-2025/', 'content': 'These insights showcase the varied factors driving AI\\'s success in healthcare. For example, targeted applications at institutions like Massachusetts General Hospital and a diagnostic chain in Mumbai have improved workflows and patient outcomes. In one instance, documentation time was cut by 41% using AI tools, while ambient microphone technology reduced time spent on documentation from 2 hours to just 15 minutes. [...] \"By allowing AI to take over many of the repetitive and rote administrative tasks that burden physicians, the physician can perform more cognitive decision-making and focus more on human connections and time spent with patients.\"\\n\\nSome of the latest developments in AI for healthcare include:\\n\\nThese innovations are transforming healthcare delivery while allowing physicians to focus more on patient care. Dr. Thomas Fuchs from Mount Sinai\\'s Icahn School of Medicine put it succinctly: [...] AI is reshaping healthcare in 2025 through these five major applications.\\n\\n### Medical Diagnosis Systems\\n\\nAt [Massachusetts General Hospital](https://www.massgeneral.org/?ref=upskillist.com) and MIT, AI algorithms have achieved impressive results in diagnosing conditions. For example, they detected lung nodules with an accuracy of 94%, compared to 65% for radiologists. Similarly, these systems showed 90% sensitivity in breast cancer detection, surpassing the 78% sensitivity of human experts.', 'score': 0.838376}, {'title': 'The Generative AI Revolution: 9 Trends Reshaping Healthcare in ...', 'url': 'https://chimecentral.org/resource-post/generative-ai-revolution', 'content': 'As we move into 2025, we anticipate a pivotal shift: Gen AI will usher in the era of the AI-Powered Clinician of the future. This transformation will redefine the talent landscape, with the primary constraint moving from technical roles to knowledge workers and their ability to embrace these new technologies. In this article, we examine both the current state of healthcare AI adoption and the transformative trends we expect to unfold over the next 12 to 24 months.\\n\\n## Our Observations [...] # The Generative AI Revolution: 9 Trends Reshaping Healthcare in 2025\\n\\nCHIME\\n\\nFoundation\\n\\nFoundation Firm Content\\n\\nAdvice From Industry Experts\\n\\nArtificial Intelligence\\n\\nDate\\n\\nTue, Feb 4, 2025, 06:00 AM\\n\\nJanuary 2025\\n\\n## Introduction [...] Advice From Industry Experts\\n\\naudio\\n\\n![CHIMECAST Hero](/_next/image?url=https%3A%2F%2Fimages.ctfassets.net%2Fopszt4tga0mx%2F5QFSix5HZAPhHEsQLNmhhH%2F2ee9ed7b1ddf1cd12b8d82e20a771f59%2FCC_Chimecast.jpg&w=3840&q=75)\\n\\nFrom Chaos to Clarity: Data Strategies for Scalable AI in Healthcare\\n\\nApr 08, 2025', 'score': 0.8286204}, {'title': 'An Overview of 2025 AI Trends in Healthcare - HealthTech Magazine', 'url': 'https://healthtechmagazine.net/article/2025/01/overview-2025-ai-trends-healthcare', 'content': 'generative AI had across industries — as well as everyday people around the world — and healthcare is no exception. [...] Some healthcare organizations are beginning to experiment with [retrieval-augmented generation](https://www.cdw.com/content/cdw/en/articles/digitalworkspace/3-areas-where-rag-implementation-can-be-improved.html). RAG is an AI framework that combines traditional vector database capabilities with LLMs. In other words, users get the benefits of a generative AI-powered chatbot that can access an organization’s more accurate and recent data. [...] Once healthcare organizations are ready to move to the next step of AI implementation, it can be helpful to collaborate with a technology partner that has experience in the realm. [CDW](https://www.cdw.com/) offers [data workshops](https://dvs.cdw.com/icx-workshop) to help healthcare organizations prepare their data for AI. We also offer [strategy engagements for modern data platforms](https://www.cdw.com/content/cdw/en/solutions/analytics/modern-data-platform.html) and deploying generative AI.', 'score': 0.77137923}, {'title': 'Top 4 Applications for Generative AI in Healthcare', 'url': 'https://blog.blackbaud.com/generative-ai-in-healthcare/', 'content': '## Utility Navigation\\n\\n## Main Navigation\\n\\n![The ENGAGE Blog by Blackbaud](https://blog.blackbaud.com/wp-content/uploads/2023/01/nav_logo.png)\\n![Blackbaud](https://blog.blackbaud.com/wp-content/themes/sgengage/img/search.svg)\\n![Blackbaud](https://blog.blackbaud.com/wp-content/themes/sgengage/img/search.svg)\\n\\nArtificial Intelligence\\n\\n# Top 4 Applications for Generative AI in Healthcare\\n\\nJanuary 22, 2025 *|*   3  min Read\\n\\nSHARE ARTICLE: [...] ![](https://blog.blackbaud.com/wp-content/uploads/2025/01/GettyImages-1441979374-e1737558811918-543x362.jpg)', 'score': 0.7634314}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have found several sources that discuss the latest advances in applications of generative AI in healthcare in 2025. I will now summarize the key points from each source.\n",
      "Action: None\n",
      "Action Input: None\u001b[0m\n",
      "Observation: None is not a valid tool, try one of [TavilySafeSearch].\n",
      "Thought:\u001b[32;1m\u001b[1;3mI will now summarize the key points from each source.\n",
      "Final Answer: \n",
      "# Latest Advances in Applications of Generative AI in Healthcare in 2025\n",
      "\n",
      "## Multimodal Models\n",
      "- Generative AI trends in 2025 indicate a shift toward multimodal models capable of analyzing and generating text, images, genomics data, and even real-time patient vitals simultaneously. This advancement will significantly improve diagnostics, clinical decision support, and medical imaging analysis. [source](https://www.johnsnowlabs.com/generative-ai-healthcare/)\n",
      "\n",
      "## Improved Workflows and Patient Outcomes\n",
      "- Targeted applications at institutions like Massachusetts General Hospital and a diagnostic chain in Mumbai have improved workflows and patient outcomes. In one instance, documentation time was cut by 41% using AI tools, while ambient microphone technology reduced time spent on documentation from 2 hours to just 15 minutes. [source](https://www.upskillist.com/blog/top-ai-agents-use-case-for-healthcare-in-2025/)\n",
      "\n",
      "## Medical Diagnosis Systems\n",
      "- At Massachusetts General Hospital and MIT, AI algorithms have achieved impressive results in diagnosing conditions. For example, they detected lung nodules with an accuracy of 94%, compared to 65% for radiologists. Similarly, these systems showed 90% sensitivity in breast cancer detection, surpassing the 78% sensitivity of human experts. [source](https://www.upskillist.com/blog/top-ai-agents-use-case-for-healthcare-in-2025/)\n",
      "\n",
      "## AI-Powered Clinician\n",
      "- As we move into 2025, we anticipate a pivotal shift: Gen AI will usher in the era of the AI-Powered Clinician of the future. This transformation will redefine the talent landscape, with the primary constraint moving from technical roles to knowledge workers and their ability to embrace these new technologies. [source](https://chimecentral.org/resource-post/generative-ai-revolution)\n",
      "\n",
      "## Retrieval-Augmented Generation (RAG)\n",
      "- Some healthcare organizations are beginning to experiment with retrieval-augmented generation (RAG). RAG is an AI framework that combines traditional vector database capabilities with LLMs. In other words, users get the benefits of a generative AI-powered chatbot that can access an organization’s more accurate and recent data. [source](https://healthtechmagazine.net/article/2025/01/overview-2025-ai-trends-healthcare)\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Your prompt here\n",
    "prompt_1 = \"\"\"\n",
    "## System\n",
    "You are a truthful news reporting bot.\n",
    "\n",
    "## Task\n",
    "- Identify and summarise the latest advances in applications of generative AI in healthcare in 2025.\n",
    "- Do not invent anything and supply your answers only on the basis of verifiable reporting.\n",
    "- Provide the relevant sources.\n",
    "- Provide your response in structured Markdown with intermediate headings and bullet-point summaries.\n",
    "\"\"\"\n",
    "\n",
    "# Run it\n",
    "response_1 = agent.run(prompt_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c70b057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Latest Advances in Applications of Generative AI in Healthcare in 2025\n",
       "\n",
       "## Multimodal Models\n",
       "- Generative AI trends in 2025 indicate a shift toward multimodal models capable of analyzing and generating text, images, genomics data, and even real-time patient vitals simultaneously. This advancement will significantly improve diagnostics, clinical decision support, and medical imaging analysis. [source](https://www.johnsnowlabs.com/generative-ai-healthcare/)\n",
       "\n",
       "## Improved Workflows and Patient Outcomes\n",
       "- Targeted applications at institutions like Massachusetts General Hospital and a diagnostic chain in Mumbai have improved workflows and patient outcomes. In one instance, documentation time was cut by 41% using AI tools, while ambient microphone technology reduced time spent on documentation from 2 hours to just 15 minutes. [source](https://www.upskillist.com/blog/top-ai-agents-use-case-for-healthcare-in-2025/)\n",
       "\n",
       "## Medical Diagnosis Systems\n",
       "- At Massachusetts General Hospital and MIT, AI algorithms have achieved impressive results in diagnosing conditions. For example, they detected lung nodules with an accuracy of 94%, compared to 65% for radiologists. Similarly, these systems showed 90% sensitivity in breast cancer detection, surpassing the 78% sensitivity of human experts. [source](https://www.upskillist.com/blog/top-ai-agents-use-case-for-healthcare-in-2025/)\n",
       "\n",
       "## AI-Powered Clinician\n",
       "- As we move into 2025, we anticipate a pivotal shift: Gen AI will usher in the era of the AI-Powered Clinician of the future. This transformation will redefine the talent landscape, with the primary constraint moving from technical roles to knowledge workers and their ability to embrace these new technologies. [source](https://chimecentral.org/resource-post/generative-ai-revolution)\n",
       "\n",
       "## Retrieval-Augmented Generation (RAG)\n",
       "- Some healthcare organizations are beginning to experiment with retrieval-augmented generation (RAG). RAG is an AI framework that combines traditional vector database capabilities with LLMs. In other words, users get the benefits of a generative AI-powered chatbot that can access an organization’s more accurate and recent data. [source](https://healthtechmagazine.net/article/2025/01/overview-2025-ai-trends-healthcare)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response_1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eab2627",
   "metadata": {},
   "source": [
    "### Exercise 2: AI Startups Landscape\n",
    "\n",
    "Goal: Track 2025’s top emerging AI startups and their innovations.\n",
    "\n",
    "- Create a prompt that instructs the agent to deliver a clean Markdown summary.\n",
    "- Tip: Ask for company names, product highlights, and sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2109cbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find information about the top emerging AI startup companies of 2025. I will use TavilySafeSearch to find this information. I will first search for a list of top AI startups in 2025, then I will search for information about their products. I will make sure to only call two websites in total.\n",
      "\n",
      "Action: TavilySafeSearch\n",
      "Action Input: \"Top emerging AI startup companies of 2025\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'AI 100: The most promising artificial intelligence startups of 2025', 'url': 'https://www.cbinsights.com/research/report/artificial-intelligence-top-startups-2025/', 'content': 'LinkedIn](https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fwww.cbinsights.com%2Fresearch%2Freport%2Fartificial-intelligence-top-startups-2025%2F&mini=true&title=AI+100%3A+The+most+promising+artificial+intelligence+startups+of+2025&summary=The+AI+space+is+evolving+at+an+unprecedented+rate.+Since+the+start+of+2024%2C+thousands+of+new+AI+companies+have+formed%2C+and+funding+to+AI+companies+has+surpassed+%24170B%2C+primarily+driven+by+titans+like+OpenAI+and+Anthropic [...] Some of the VCs we spoke with see specialization as the way of the future. Lila Tretikov, Partner and Head of AI Strategy at [New Enterprise Associates](https://www.cbinsights.com/investor/new-enterprise-associates) (a lead investor for [Twelve Labs](https://www.cbinsights.com/company/twelvelabs), [World Labs](https://www.cbinsights.com/company/world-labs), and [Orby AI](https://www.cbinsights.com/company/orby-ai)), told us: [...] *   **Auto & mobility:**AI applications for autonomous vehicles, transportation optimization, fleet management, and mobility services. Companies like [Wayve](https://www.cbinsights.com/company/wayve-1) are developing AI systems that use LLMs to provide real-time natural language explanations of driving decisions, helping improve users’ confidence.', 'score': 0.93309647}, {'title': '18 AI Startups to Watch in 2025 - Backlinko', 'url': 'https://backlinko.com/ai-startups', 'content': '*   [1\\\\. VEED](https://backlinko.com/ai-startups#1-veed)\\n*   [2\\\\. Fliki](https://backlinko.com/ai-startups#2-fliki)\\n*   [3\\\\. PhotoRoom](https://backlinko.com/ai-startups#3-photo-room)\\n*   [4\\\\. Codeium](https://backlinko.com/ai-startups#4-codeium)\\n*   [5\\\\. Suno](https://backlinko.com/ai-startups#5-suno)\\n*   [6\\\\. Anthropic](https://backlinko.com/ai-startups#6-anthropic)\\n*   [7\\\\. Gamma](https://backlinko.com/ai-startups#7-gamma)\\n*   [8\\\\. Fathom](https://backlinko.com/ai-startups#8-fathom) [...] *   [9\\\\. Vidnoz](https://backlinko.com/ai-startups#9-vidnoz)\\n*   [10\\\\. Udio](https://backlinko.com/ai-startups#10-udio)\\n*   [11\\\\. Perplexity](https://backlinko.com/ai-startups#11-perplexity)\\n*   [12\\\\. Ideogram](https://backlinko.com/ai-startups#12-ideogram)\\n*   [13\\\\. Harvey](https://backlinko.com/ai-startups#13-harvey)\\n*   [14\\\\. Liner](https://backlinko.com/ai-startups#14-liner)\\n*   [15\\\\. Otter.ai](https://backlinko.com/ai-startups#15-otter-ai)', 'score': 0.9125066}, {'title': '60 Growing AI Companies & Startups (2025) - Exploding Topics', 'url': 'https://explodingtopics.com/blog/ai-startups', 'content': '*   [Interactions](https://explodingtopics.com/blog/ai-startups#26-interactions)\\n*   [Fireflies.ai](https://explodingtopics.com/blog/ai-startups#27-firefliesai)\\n*   [Otter AI](https://explodingtopics.com/blog/ai-startups#28-otter-ai)\\n*   [AssemblyAI](https://explodingtopics.com/blog/ai-startups#29-assemblyai)\\n*   [LogicMonitor](https://explodingtopics.com/blog/ai-startups#30-logicmonitor)\\n*   [Groq](https://explodingtopics.com/blog/ai-startups#31-groq) [...] *   [DeepL](https://explodingtopics.com/blog/ai-startups#1-deepl)\\n*   [Frame AI](https://explodingtopics.com/blog/ai-startups#2-frame-ai)\\n*   [Uizard](https://explodingtopics.com/blog/ai-startups#3-uizard)\\n*   [Moveworks](https://explodingtopics.com/blog/ai-startups#4-moveworks)\\n*   [Databricks](https://explodingtopics.com/blog/ai-startups#5-databricks)\\n*   [Synthesia](https://explodingtopics.com/blog/ai-startups#6-synthesia) [...] *   [Tabnine](https://explodingtopics.com/blog/ai-startups#44-tabnine)\\n*   [FeedHive](https://explodingtopics.com/blog/ai-startups#45-feedhive)\\n*   [Roboflow](https://explodingtopics.com/blog/ai-startups#46-roboflow)\\n*   [PhotoPrism](https://explodingtopics.com/blog/ai-startups#47-photoprism)\\n*   [Edge Impulse](https://explodingtopics.com/blog/ai-startups#48-edge-impulse)\\n*   [Docsumo](https://explodingtopics.com/blog/ai-startups#49-docsumo)', 'score': 0.87605256}, {'title': 'Forbes 2025 AI 50 List - Top Artificial Intelligence Companies Ranked', 'url': 'https://www.forbes.com/lists/ai50/', 'content': '[reportedly](https://www.businessinsider.com/mira-murati-new-startup-thinking-machine-labs-valuation-2025-2) raising $1 billion at a valuation of about $9 billion. Meanwhile, Fei Fei Li, known as the “godmother of AI”, has launched her own startup too, World Labs ($291.5 million raised), to develop models that can understand physical spaces. And then there’s enterprise AI company Writer ($326 million raised), which is training its own models to handle mundane business tasks like writing', 'score': 0.8752871}, {'title': 'AI (Artificial Intelligence) Startups funded by Y Combinator (YC) 2025', 'url': 'https://www.ycombinator.com/companies/industry/ai', 'content': 'critical business insights and operational efficiency. Its data-centric infrastructure platform leverages RLHF (Reinforced Learning with Human Feedback) to help organizations build the strongest AI models that supercharge their business, with customers across industries including Meta, Microsoft, U.S. Army, DoD’s Defense Innovation Unit, Open AI, General Motors, Toyota Research Institute, Brex, Instacart and Flexport. artificial-intelligence', 'score': 0.8732259}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe first website from CB Insights seems to have a comprehensive list of top AI startups in 2025. It also seems to have some information about the companies and their products. The second website from Backlinko also has a list of AI startups, but it doesn't seem to have as much information about the companies and their products. I will use the first website to select three companies and then search for more information about their products.\n",
      "\n",
      "Action: TavilySafeSearch\n",
      "Action Input: \"Twelve Labs AI startup 2025 product\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': \"S.Korea's Twelve Labs ranks among world's top 50 generative AI ...\", 'url': 'https://www.twelvelabs.io/blog/genai-50-the-most-promising-generative-artificial-intelligence-startups-of-2023', 'content': \"![](https://framerusercontent.com/images/RI12VW53mjFT0vc3cYDbWwDeBE.png)\\n\\nEffective June 4, 2025, â\\x80\\x9cGenerateâ\\x80\\x9d has been renamed to â\\x80\\x9cAnalyze.â\\x80\\x9d See **Release Notes** for more information.\\n\\nNews\\n\\nNews\\n\\nNews\\n\\n### S.Korea's Twelve Labs ranks among world's top 50 generative AI startups\\n\\n![](https://framerusercontent.com/images/n2ARRL0fUSeOJQS6lH8YGbU.png)\\n![](https://framerusercontent.com/images/n2ARRL0fUSeOJQS6lH8YGbU.png)\\n\\nThe Korea Economic Daily\\n\\nThe Korea Economic Daily [...] ![](https://framerusercontent.com/images/RI12VW53mjFT0vc3cYDbWwDeBE.png)\\n\\nEffective June 4, 2025, â\\x80\\x9cGenerateâ\\x80\\x9d has been renamed to â\\x80\\x9cAnalyze.â\\x80\\x9d See **Release Notes** for more information.\\n\\nProducts\\n\\nEnterprise\\n\\nResearch\\n\\nDevelopers\\n\\nCompany\\n\\nPlayground\\n\\nTalk to Sales\\n\\n![](https://framerusercontent.com/images/RI12VW53mjFT0vc3cYDbWwDeBE.png)\\n\\nEffective June 4, 2025, â\\x80\\x9cGenerateâ\\x80\\x9d has been renamed to â\\x80\\x9cAnalyze.â\\x80\\x9d See **Release Notes** for more information. [...] ![](https://framerusercontent.com/images/qGq0H3wpDVKaGWZPoCjFjnKI8s.png)\\n\\nÂ© 2021\\n\\n-\\n\\n2025\\n\\nTwelveLabs, Inc. All Rights Reserved\\n\\n![Footer accent](https://framerusercontent.com/images/1QdtTVJZbEIsmtSXybHYXKkJSE.svg)\\n\\nProduct\\n\\n[Products Overview](../product/product-overview)\\n\\n[Models Overview](../product/models-overview)\\n\\n[Search](../product/video-search)\\n\\n[Analyze](../product/analyze)\\n\\n[Embed](../product/embed)\\n\\n[Pricing](../pricing)\\n\\nSocial\", 'score': 0.81875163}, {'title': 'AI 100: The most promising artificial intelligence startups of 2025', 'url': 'https://www.cbinsights.com/research/report/artificial-intelligence-top-startups-2025/', 'content': 'Some of the VCs we spoke with see specialization as the way of the future. Lila Tretikov, Partner and Head of AI Strategy at [New Enterprise Associates](https://www.cbinsights.com/investor/new-enterprise-associates) (a lead investor for [Twelve Labs](https://www.cbinsights.com/company/twelvelabs), [World Labs](https://www.cbinsights.com/company/world-labs), and [Orby AI](https://www.cbinsights.com/company/orby-ai)), told us:', 'score': 0.7574541}, {'title': 'TwelveLabs | Home', 'url': 'https://www.twelvelabs.io/', 'content': '![](https://framerusercontent.com/images/RI12VW53mjFT0vc3cYDbWwDeBE.png)\\n\\nEffective June 4, 2025, â\\x80\\x9cGenerateâ\\x80\\x9d has been renamed to â\\x80\\x9cAnalyze.â\\x80\\x9d See **Release Notes** for more information.\\n\\nProducts\\n\\nEnterprise\\n\\nResearch\\n\\nDevelopers\\n\\nCompany\\n\\nPlayground\\n\\nTalk to Sales\\n\\n![](https://framerusercontent.com/images/RI12VW53mjFT0vc3cYDbWwDeBE.png)\\n\\nEffective June 4, 2025, â\\x80\\x9cGenerateâ\\x80\\x9d has been renamed to â\\x80\\x9cAnalyze.â\\x80\\x9d See **Release Notes** for more information. [...] ![](https://framerusercontent.com/images/RI12VW53mjFT0vc3cYDbWwDeBE.png)\\n\\nEffective June 4, 2025, â\\x80\\x9cGenerateâ\\x80\\x9d has been renamed to â\\x80\\x9cAnalyze.â\\x80\\x9d See **Release Notes** for more information.\\n\\n![](https://framerusercontent.com/images/RI12VW53mjFT0vc3cYDbWwDeBE.png)\\n\\nEffective June 4, 2025, â\\x80\\x9cGenerateâ\\x80\\x9d has been renamed to â\\x80\\x9cAnalyze.â\\x80\\x9d See **Release Notes** for more information.\\n\\n# Search and Understand Your Videos - with AI', 'score': 0.75312227}, {'title': 'Twelve Labs is building AI that can analyze and search through videos', 'url': 'https://www.twelvelabs.io/blog/twelve-labs-is-building-ai-that-can-analyze-and-search-through-videos', 'content': '![](https://framerusercontent.com/images/qGq0H3wpDVKaGWZPoCjFjnKI8s.png)\\n\\nÂ© 2021\\n\\n-\\n\\n2025\\n\\nTwelveLabs, Inc. All Rights Reserved\\n\\n![Footer accent](https://framerusercontent.com/images/1QdtTVJZbEIsmtSXybHYXKkJSE.svg)\\n\\nProduct\\n\\n[Products Overview](../product/product-overview)\\n\\n[Models Overview](../product/models-overview)\\n\\n[Search](../product/video-search)\\n\\n[Generate](../product/generate)\\n\\n[Embed](../product/embed)\\n\\n[Pricing](../pricing)\\n\\nSocial [...] [Acceptable Use and Conduct Policy](../aup)\\n\\n[Patents](../patents)\\n\\n![](https://framerusercontent.com/images/qGq0H3wpDVKaGWZPoCjFjnKI8s.png)\\n\\nÂ© 2021\\n\\n-\\n\\n2025\\n\\nTwelveLabs, Inc. All Rights Reserved\\n\\n![Footer accent](https://framerusercontent.com/images/1QdtTVJZbEIsmtSXybHYXKkJSE.svg)\\n\\nProduct\\n\\n[Products Overview](../product/product-overview)\\n\\n[Models Overview](../product/models-overview)\\n\\n[Search](../product/video-search)\\n\\n[Generate](../product/generate)\\n\\n[Embed](../product/embed) [...] Products\\n\\nEnterprise\\n\\nResearch\\n\\nDevelopers\\n\\nCompany\\n\\nPlayground\\n\\nTalk to Sales\\n\\nNews\\n\\nNews\\n\\nNews\\n\\n### Twelve Labs is building AI that can analyze and search through videos\\n\\n![](https://framerusercontent.com/images/3IysZz23Kg1WGIEEOBIuBL2eV0o.png)\\n![](https://framerusercontent.com/images/3IysZz23Kg1WGIEEOBIuBL2eV0o.png)\\n\\nKyle Wiggers\\n\\nKyle Wiggers\\n\\nKyle Wiggers\\n\\nStartup Twelve Labs is building models and tools to help companies search through and analyze video content.', 'score': 0.7520312}, {'title': 'Twelve Labs pioneers AI video intelligence on AWS - AWS Startups', 'url': 'https://aws.amazon.com/startups/learn/seeing-is-understanding-twelve-labs-pioneers-ai-video-intelligence-on-aws?lang=en-US', 'content': 'Twelve Labs is a South Korean startup focused on AI-powered video intelligence. The company was co-founded by\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mTwelve Labs seems to have a product named \"Analyze\" which was previously known as \"Generate\". This product appears to be designed to help companies search through and analyze video content. I will now search for information about the second company, World Labs.\n",
      "\n",
      "Action: TavilySafeSearch\n",
      "Action Input: \"World Labs AI startup 2025 product\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': \"World Labs' AI can generate interactive 3D scenes from a single photo\", 'url': 'https://techcrunch.com/2024/12/02/world-labs-ai-can-generate-interactive-3d-scenes-from-a-single-photo/', 'content': 'World Labs, which launched earlier this year, has [raised](https://techcrunch.com/2024/08/14/nea-led-a-100m-round-into-fei-fei-lis-new-ai-startup-now-valued-at-over-1b/) $230 million in venture capital from investors, including Andreessen Horowitz (a16z), Ashton Kutcher, Intel Capital, AMD Ventures, and Eric Schmidt. Valued at over $1 billion, the company hopes to have its first product ready in 2025. [...] ### [Elon Musk tries to stick to spaceships](https://techcrunch.com/2025/06/01/elon-musk-tries-to-stick-to-spaceships/)\\n\\n[Elon Musk tries to stick to spaceships](https://techcrunch.com/2025/06/01/elon-musk-tries-to-stick-to-spaceships/)\\n\\n### [Thousands of Netflix fans gather for Tudum](https://techcrunch.com/2025/06/01/thousands-of-netflix-fans-gather-for-tudum/)\\n\\n[Thousands of Netflix fans gather for Tudum](https://techcrunch.com/2025/06/01/thousands-of-netflix-fans-gather-for-tudum/) [...] [World Labs](https://techcrunch.com/tag/world-labs/), the startup founded by AI pioneer Fei-Fei Li, has [unveiled](https://www.worldlabs.ai/blog) its first project: an AI system that can generate video game-like, 3D scenes from a single image.', 'score': 0.85216236}, {'title': 'AI Startup World Labs Launches With $230M From Andreessen ...', 'url': 'https://news.crunchbase.com/ai/world-labs-launches-a16z-nventures/', 'content': '*   [VC Funding Reports](http://0.0.7.232/)\\n    *   [2025](https://news.crunchbase.com/ai/world-labs-launches-a16z-nventures/#)\\n        *   [Q1 2025](https://news.crunchbase.com/ai/world-labs-launches-a16z-nventures/#)\\n        *   [Q1 2025 Global](https://news.crunchbase.com/venture/global-funding-strong-q1-2025-ai-data/)\\n        *   [Q1 2025 North America](https://news.crunchbase.com/venture/north-american-startup-investment-spiked-q1-2025-ai-ma/) [...] *   [Q1 2025 Asia](https://news.crunchbase.com/venture/asia-startup-funding-sags-q1-2025-ai/)\\n        *   [Q1 2025 Latin America](https://news.crunchbase.com/venture/latin-america-startup-funding-fell-q1-2025/)\\n        *   [Q1 2025 Europe](https://news.crunchbase.com/venture/european-funding-flat-q1-2025/)\\n    *   [2024](https://news.crunchbase.com/ai/world-labs-launches-a16z-nventures/#)\\n        *   [Q4 2024](https://news.crunchbase.com/ai/world-labs-launches-a16z-nventures/#) [...] [4 Reasons Every High-Growth Startup Needs A Founder’s Office](https://news.crunchbase.com/startups/four-reasons-for-founders-office-martinez-abacum/)\\n--------------------------------------------------------------------------------------------------------------------------------\\n\\n[Guest Author](https://news.crunchbase.com/author/guest-author/)\\n\\nApril 28, 2025', 'score': 0.8351749}, {'title': \"Fei-Fei Li's World Labs comes out of stealth with $230M in funding\", 'url': 'https://techcrunch.com/2024/09/13/fei-fei-lis-world-labs-comes-out-of-stealth-with-230m-in-funding/', 'content': 'Li’s company, which hopes to have its first product ready in 2025, aims to build AI models that understand and interact with the 3D world. World Labs is developing what it calls “large world models” that will be used by professionals such as artists, designers, developers, and engineers. Martin Casado, a general partner at Andreessen Horowitz, [told Wired](https://www.wired.com/story/plaintext-the-godmother-of-ai-wants-everyone-to-be-a-world-builder/) that World Labs’ customers could include [...] ### [LinkedIn CEO says AI writing assistant is not as popular as expected](https://techcrunch.com/2025/06/22/linkedin-ceo-says-ai-writing-assistant-is-not-as-popular-as-expected/)\\n\\n![TechCrunch Logo](https://techcrunch.com/wp-content/themes/tc-24/dist/svg/tc-logo.svg)\\n\\n© 2025 TechCrunch Media LLC. [...] ### [Toma’s AI voice agents have taken off at car dealerships — and attracted funding from a16z](https://techcrunch.com/2025/06/05/tomas-ai-voice-agents-have-taken-off-at-car-dealerships-and-attracted-funding-from-a16z/)\\n\\n![Sprinter Health founders](https://techcrunch.com/wp-content/uploads/2025/05/Founder-Photo_Sprinter-Health.jpg?w=525)', 'score': 0.8252664}, {'title': 'World Labs: Pioneering the Future of Spatial Intelligence AI - AIX', 'url': 'https://aiexpert.network/world-labs/', 'content': \"The company's strategic partnerships and development milestones are on track, with plans to unveil their first products in 2025, aiming to\", 'score': 0.8014549}, {'title': \"Fei-Fei Li's world labs debuts groundbreaking 3D AI\", 'url': 'https://dig.watch/updates/fei-fei-lis-world-labs-debuts-groundbreaking-3d-ai', 'content': 'The company plans to refine its system further and release its first product in 2025, marking a significant step in the evolution of interactive', 'score': 0.80014634}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mWorld Labs is developing an AI system that can generate interactive 3D scenes from a single image. This product is expected to be ready in 2025 and is aimed at professionals such as artists, designers, developers, and engineers. Now, I will search for information about the third company, Orby AI.\n",
      "\n",
      "Action: TavilySafeSearch\n",
      "Action Input: \"Orby AI startup 2025 product\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'Orby AI Unveils Cutting-Edge Generic Agent Framework and Self ...', 'url': 'https://www.prnewswire.com/news-releases/orby-ai-unveils-cutting-edge-generic-agent-framework-and-self-adaptive-interface-learning-achieving-state-of-the-art-ai-agent-performance-302384464.html', 'content': 'MOUNTAIN VIEW, Calif., Feb. 25, 2025 /PRNewswire/ --\\xa0[Orby AI](https://c212.net/c/link/?t=0&l=en&o=4369450-1&h=1503884962&u=https%3A%2F%2Fwww.orby.ai%2F&a=Orby+AI), a leading AI Agent and Automation Discovery platform company, today announced the launch of its Generic Agent Framework and Self-Adaptive Interface Learning (SAIL) technique, setting new industry benchmarks for AI agent performance. With this innovation, Orby AI\\'s agents achieve state-of-the-art (SOTA) results on industry-standard [...] ![Orby AI Named to the 2025 CB Insights\\' List of the 100 Most Innovative AI Startups](https://mma.prnewswire.com/media/2677493/Orby_AI_100.jpg?w=300)\\n\\n### Orby AI Named to the 2025 CB Insights\\' List of the 100 Most Innovative AI Startups\\n\\nCB Insights named Orby AI to its ninth annual AI 100, showcasing the 100 most promising private artificial intelligence companies in the world. \"The... [...] ![PR Newswire: news distribution, targeting and monitoring](/content/dam/prnewswire/homepage/prn_cision_logo_mobile.png \"PR Newswire: news distribution, targeting and monitoring\")\\n\\n[Contact Us](/contact-us/)\\n\\n[888-776-0942](tel:+1-888-776-0942)\\n  \\nfrom 8 AM - 10 PM ET\\n\\n# Orby AI Unveils Cutting-Edge Generic Agent Framework and Self-Adaptive Interface Learning, Achieving State-of-the-Art AI Agent Performance\\n\\n## News provided by\\n\\nFeb 25, 2025, 09:00 ET\\n\\n## Share this article', 'score': 0.8430832}, {'title': 'Orby AI | AI Agent & Enterprise Automation Platform Company', 'url': 'https://www.orby.ai/', 'content': '###### AI 100: The most promising artificial intelligence startups of 2025\\n\\nOrby AI selected as a winner in the Process Automation category\\n\\n[Learn more](https://www.cbinsights.com/research/report/artificial-intelligence-top-startups-2025/)\\n\\n![Image 3](https://cdn.prod.website-files.com/67175f9cabb191b424af75e8/68121ff3fce6c8a5223c6d5a_AI%20100-%20The%20most%20promising%20artificial%20intelligence%20startups%20of%202025%20Img.png)', 'score': 0.7777226}, {'title': 'About Orby AI | Revolutionizing Enterprise Automation', 'url': 'https://www.orby.ai/about-us', 'content': '[Insurance Brokerages & Agencies](https://www.orby.ai/solutions-for-insurance-brokerages)[Real Estate](https://www.orby.ai/about-us#)[Technology](https://www.orby.ai/about-us#)[Legal Services](https://www.orby.ai/about-us#)\\n\\n###### AI 100: The most promising artificial intelligence startups of 2025\\n\\nOrby AI selected as a winner in the Process Automation category\\n\\n[Learn more](https://www.cbinsights.com/research/report/artificial-intelligence-top-startups-2025/) [...] ![Image 21](https://cdn.prod.website-files.com/67175f9cabb191b424af75e8/676134939727de717e07fd24_news-card-4.avif)\\n\\n### Orby AI Named to 2025 Enterprise Tech 30 List by Wing Venture Capital\\n\\n[This is some text inside of a div block.](https://www.orby.ai/resources/orby-ai-named-12-in-early-stage-in-enterprise-tech-30)\\n\\n![Image 22](https://cdn.prod.website-files.com/67175f9cabb191b424af75e8/673af983982a1bc3c7ab1165_resource-card-image-1.svg) [...] ![Image 3](https://cdn.prod.website-files.com/67175f9cabb191b424af75e8/68121ff3fce6c8a5223c6d5a_AI%20100-%20The%20most%20promising%20artificial%20intelligence%20startups%20of%202025%20Img.png)\\n\\n[Case Studies](https://www.orby.ai/case-studies)[About Us](https://www.orby.ai/about-us)[Resources](https://www.orby.ai/resources)\\n\\n[SIGN IN](https://web-app.orby.ai/login)[Request Demo](https://www.orby.ai/request-demo)\\n\\nWho Are We?\\n===========', 'score': 0.76701033}, {'title': 'We are thrilled to announce that Orby AI has been recognized in the ...', 'url': 'https://www.linkedin.com/posts/orby-ai_we-are-thrilled-to-announce-that-orby-ai-activity-7310311583044222976-UAjZ', 'content': 'We are thrilled to announce that Orby AI has been recognized in the 2025 Enterprise Tech 30 list! So honored to be among such a great group', 'score': 0.7147281}, {'title': 'Orby AI nominated #12 in Early Stage | Enterprise Tech 30', 'url': 'https://www.enterprisetech30.com/list/orby-ai', 'content': '[![Image 17](https://cdn.prod.website-files.com/6441849561895f1cf617a968/67e1a8ca7d98e573b1bbecfd_67d9e418e925e4daef9a7d41_67d8bbdf56e02caf655bd1f6_Orby%252520ET30-2025_Social.jpeg)](https://cdn.prod.website-files.com/6441849561895f1cf617a968/67e1a8ca7d98e573b1bbecfd_67d9e418e925e4daef9a7d41_67d8bbdf56e02caf655bd1f6_Orby%252520ET30-2025_Social.jpeg)\\n\\n[Close](https://www.enterprisetech30.com/list/orby-ai#) [...] *   [![Image 15](https://cdn.prod.website-files.com/643f233757edc323870e651f/64417ed4b27cb254787103c0_twitter-icon.svg)](https://twitter.com/wing_vc)\\n*   [![Image 16](https://cdn.prod.website-files.com/643f233757edc323870e651f/64417ed443e27f2a75655946_linkedin-icon.svg)](https://www.linkedin.com/company/wing-venture-capital/)\\n\\n© 2025 Wing VC, Palo Alto CA\\n\\n[Privacy Policy](https://www.wing.vc/privacy-policy)\\n\\nShare Orby AI being named to the ET30\\n------------------------------------- [...] Mountain View, CA\\n\\n[orby.ai](https://www.orby.ai/)\\n\\n[LinkedIn](https://www.linkedin.com/company/orby-ai)\\n\\n[Twitter/X](https://x.com/OrbyAI)\\n\\nTotal Raised: $34.5M\\n\\n Valuation: N/A\\n\\n Founded: 2022\\n\\n Employees: 50\\n\\n### Category\\n\\nHorizontal / Vertical Applications\\n\\nEarly Stage\\n\\nNews &Announcements\\n-------------------\\n\\nFebruary 25, 2025', 'score': 0.6780931}]\u001b[0m\n",
      "Thought:"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, you requested 9187 tokens (7187 in the messages, 2000 in the completion). Please reduce the length of the messages or completion.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m prompt_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124mList three of the top emerging AI startup companies of 2025.\u001b[39m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124m- Summarise the results clearly in well-formed Markdown.\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Run it\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m response_2 \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_2\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     emit_warning()\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain/chains/base.py:603\u001b[0m, in \u001b[0;36mChain.run\u001b[0;34m(self, callbacks, tags, metadata, *args, **kwargs)\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    602\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`run` supports only one positional argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 603\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m[\n\u001b[1;32m    604\u001b[0m         _output_key\n\u001b[1;32m    605\u001b[0m     ]\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m(kwargs, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, tags\u001b[38;5;241m=\u001b[39mtags, metadata\u001b[38;5;241m=\u001b[39mmetadata)[\n\u001b[1;32m    609\u001b[0m         _output_key\n\u001b[1;32m    610\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     emit_warning()\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain/chains/base.py:386\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    384\u001b[0m }\n\u001b[0;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain/chains/base.py:167\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    166\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    168\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain/chains/base.py:157\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 157\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    162\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    163\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain/agents/agent.py:1620\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;66;03m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[0;32m-> 1620\u001b[0m     next_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_take_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1623\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1624\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1625\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1626\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1627\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[1;32m   1628\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_return(\n\u001b[1;32m   1629\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[38;5;241m=\u001b[39mrun_manager\n\u001b[1;32m   1630\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain/agents/agent.py:1326\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1317\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_take_next_step\u001b[39m(\n\u001b[1;32m   1318\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1319\u001b[0m     name_to_tool_map: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, BaseTool],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1323\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1324\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[AgentFinish, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[AgentAction, \u001b[38;5;28mstr\u001b[39m]]]:\n\u001b[1;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume_next_step(\n\u001b[0;32m-> 1326\u001b[0m         \u001b[43m[\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m            \u001b[49m\u001b[43ma\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iter_next_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m                \u001b[49m\u001b[43mname_to_tool_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcolor_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m                \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m                \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   1336\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain/agents/agent.py:1354\u001b[0m, in \u001b[0;36mAgentExecutor._iter_next_step\u001b[0;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[1;32m   1351\u001b[0m     intermediate_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_intermediate_steps(intermediate_steps)\n\u001b[1;32m   1353\u001b[0m     \u001b[38;5;66;03m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[0;32m-> 1354\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_agent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplan\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mintermediate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1357\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m OutputParserException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1360\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_parsing_errors, \u001b[38;5;28mbool\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain/agents/agent.py:800\u001b[0m, in \u001b[0;36mAgent.plan\u001b[0;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Given input, decided what to do.\u001b[39;00m\n\u001b[1;32m    789\u001b[0m \n\u001b[1;32m    790\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    797\u001b[0m \u001b[38;5;124;03m    Action specifying what tool to use.\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    799\u001b[0m full_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_full_inputs(intermediate_steps, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 800\u001b[0m full_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfull_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_parser\u001b[38;5;241m.\u001b[39mparse(full_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain/chains/llm.py:319\u001b[0m, in \u001b[0;36mLLMChain.predict\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, callbacks: Callbacks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    305\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format prompt with kwargs and pass to LLM.\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \n\u001b[1;32m    307\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m            completion = llm.predict(adjective=\"funny\")\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_key]\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:191\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.warning_emitting_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    189\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    190\u001b[0m     emit_warning()\n\u001b[0;32m--> 191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain/chains/base.py:386\u001b[0m, in \u001b[0;36mChain.__call__\u001b[0;34m(self, inputs, return_only_outputs, callbacks, tags, metadata, run_name, include_run_info)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the chain.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \n\u001b[1;32m    356\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;124;03m        `Chain.output_keys`.\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    379\u001b[0m config \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks,\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m: tags,\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: run_name,\n\u001b[1;32m    384\u001b[0m }\n\u001b[0;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRunnableConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_only_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_run_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_run_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain/chains/base.py:167\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    166\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n\u001b[0;32m--> 167\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    168\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(outputs)\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m include_run_info:\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain/chains/base.py:157\u001b[0m, in \u001b[0;36mChain.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_inputs(inputs)\n\u001b[1;32m    156\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 157\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(inputs)\n\u001b[1;32m    160\u001b[0m     )\n\u001b[1;32m    162\u001b[0m     final_outputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprep_outputs(\n\u001b[1;32m    163\u001b[0m         inputs, outputs, return_only_outputs\n\u001b[1;32m    164\u001b[0m     )\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain/chains/llm.py:127\u001b[0m, in \u001b[0;36mLLMChain._call\u001b[0;34m(self, inputs, run_manager)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_call\u001b[39m(\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    124\u001b[0m     inputs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any],\n\u001b[1;32m    125\u001b[0m     run_manager: Optional[CallbackManagerForChainRun] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    126\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m--> 127\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate_outputs(response)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain/chains/llm.py:139\u001b[0m, in \u001b[0;36mLLMChain.generate\u001b[0;34m(self, input_list, run_manager)\u001b[0m\n\u001b[1;32m    137\u001b[0m callbacks \u001b[38;5;241m=\u001b[39m run_manager\u001b[38;5;241m.\u001b[39mget_child() \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, BaseLanguageModel):\n\u001b[0;32m--> 139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    140\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mbind(stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_kwargs)\u001b[38;5;241m.\u001b[39mbatch(\n\u001b[1;32m    147\u001b[0m         cast(\u001b[38;5;28mlist\u001b[39m, prompts), {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m: callbacks}\n\u001b[1;32m    148\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:957\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    949\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    950\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    955\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    956\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 957\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:776\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[1;32m    774\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    775\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 776\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    782\u001b[0m         )\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    784\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py:1022\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1022\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1023\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1024\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1026\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain_community/chat_models/openai.py:476\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    470\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    471\u001b[0m params \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    472\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m: stream} \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[1;32m    474\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    475\u001b[0m }\n\u001b[0;32m--> 476\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/langchain_community/chat_models/openai.py:387\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Use tenacity to retry the completion call.\"\"\"\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_openai_v1():\n\u001b[0;32m--> 387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m retry_decorator \u001b[38;5;241m=\u001b[39m _create_retry_decorator(\u001b[38;5;28mself\u001b[39m, run_manager\u001b[38;5;241m=\u001b[39mrun_manager)\n\u001b[1;32m    391\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_completion_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/openai/_utils/_utils.py:287\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py:925\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    922\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    923\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    924\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[1;32m    962\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[1;32m    963\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    965\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/openai/_base_client.py:1249\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1236\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1237\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1244\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1245\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1246\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1247\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1248\u001b[0m     )\n\u001b[0;32m-> 1249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/nlp.venv/lib/python3.12/site-packages/openai/_base_client.py:1037\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1034\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1036\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1037\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"This model's maximum context length is 8192 tokens. However, you requested 9187 tokens (7187 in the messages, 2000 in the completion). Please reduce the length of the messages or completion.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}"
     ]
    }
   ],
   "source": [
    "# Your prompt here\n",
    "prompt_2 = \"\"\"\n",
    "List three of the top emerging AI startup companies of 2025.\n",
    "\n",
    "- For each company, provide product highlight and provide sources.\n",
    "- Call no more than two websites in total.\n",
    "- Summarise the results clearly in well-formed Markdown.\n",
    "\"\"\"\n",
    "\n",
    "# Run it\n",
    "response_2 = agent.run(prompt_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324a01a2",
   "metadata": {},
   "source": [
    "This call continues to get too inflated even after several rounds of attempting to further restrict. Aborting here to avoid running out of funds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504bd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(response_2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b8fda",
   "metadata": {},
   "source": [
    "### Exercice 3: Compare Two Tech Products\n",
    "- **Prompt idea:** Compare the key features, pricing, and reviews of OpenAI’s ChatGPT Team and Anthropic’s Claude Pro.\n",
    "- Ensure the agent outputs a structured response in Markdown.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58ff7f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo provide a comprehensive comparison between OpenAI's ChatGPT Team and Anthropic's Claude Pro, I will need to gather the latest information on their offerings, features, pricing, and reviews. \n",
      "\n",
      "Action: TavilySafeSearch  \n",
      "Action Input: \"OpenAI ChatGPT Team features pricing reviews 2023\"  \n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'ChatGPT Review: Analysis of Features, Pricing, and Use Cases', 'url': 'https://www.bitdegree.org/ai/chatgpt-review', 'content': \"![Image 15: ChatGPT review: API pricing page.](https://assets.bitdegree.org/images/chatgpt-review-api-pricing-v1.jpg)\\n\\nThe latest model, **GPT-4o**, which is the most advanced multimodal model yet. It's **faster and cheaper than other API versions**, featuring stronger vision capabilities. GPT-4o has a 128K context and an October 2023 knowledge cutoff. The pricing for GPT-4o is $5.00 per 1M tokens for input and $15.00 per 1M tokens for output. [...] Lastly, **GPT-4 Turbo** offers a wide range of skills and knowledge up to April 2023. It is considered a **powerful and cost-effective alternative** to GPT-4, with input and output rates of $10 and $30 per 1M tokens, respectively. This model is popular among users who need high-quality performance at a lower cost.\\n\\nIn conclusion, I recommend checking the full pricing details and exploring the features of each model to find the best fit for your needs.\\n\\nHow to Use ChatGPT?\\n------------------- [...] The “Te\\xadam” tier is further up. It is priced at $25 per person per month. This is made for te\\xadams at work. It gives more data use and te\\xadam features like shared workspaces and an admin console. This tier also keeps team data private, excluding it from AI model training.\", 'score': 0.8091708}, {'title': 'Introducing ChatGPT Team - OpenAI', 'url': 'https://openai.com/index/introducing-chatgpt-team/', 'content': 'ChatGPT Team costs $25/month per user when billed annually, or $30/month per user when billed monthly. You can [explore the details](https://openai.com/chatgpt/team/) or get started now by upgrading in your ChatGPT settings.\\n\\n*   [Explore ChatGPT Team](https://openai.com/chatgpt/team/)\\n*   [Start now(opens in a new window)](https://chatgpt.com/#team-pricing)\\n\\n*   [ChatGPT](https://openai.com/news/?tags=chatgpt)\\n*   [2024](https://openai.com/news/?tags=2024)\\n\\nReferences\\n---------- [...] *   Access to GPT‑4 with 32K context window\\n*   Tools like DALL·E 3, GPT‑4 with Vision, Browsing, Advanced Data Analysis—with higher message caps\\n*   No training on your business data or conversations\\n*   Secure workspace for your team\\n*   Create and share custom GPTs with your workspace\\n*   Admin console for workspace and team management\\n*   Early access to new features and improvements\\n\\n*   [Start now(opens in a new window)](https://chatgpt.com/#pricing) [...] *   [Enterprise](https://openai.com/chatgpt/enterprise/)\\n    *   [Education](https://openai.com/chatgpt/education/)\\n    *   [Pricing](https://openai.com/chatgpt/pricing/)\\n    *   [Download](https://openai.com/chatgpt/download/)\\n    \\n*   Sora\\n    \\n    Back to main menu\\n    \\n    *   [Sora Overview](https://openai.com/sora/)\\n    *   [Features](https://openai.com/sora/#features)\\n    *   [Pricing](https://openai.com/sora/#pricing)', 'score': 0.72698855}, {'title': 'Pricing - ChatGPT - OpenAI', 'url': 'https://openai.com/chatgpt/pricing/', 'content': 'Yes. Through OpenAI for Nonprofits, nonprofits can now access a 20% discount on [ChatGPT Team](https://openai.com/chatgpt/team/) ($20 per month per user for the annual plan and $24 per month per user for the monthly plan). Larger nonprofits ready for large-scale deployment can [contact our sales team](https://openai.com/contact-sales/) to access a 25% discount on [ChatGPT Enterprise](https://openai.com/chatgpt/enterprise/).\\n\\n### How many users are supported on each subscription plan? [...] *   Access to OpenAI o3‑pro, which uses more compute for the best answers to the hardest questions\\n\\n*   Extended access to deep research\\n\\n*   Extended access to Sora video generation\\n\\n*   Access to a research preview of Operator\\n\\n*   Access to research preview of Codex agent\\n\\n_Unlimited subject to abuse guardrails._[_Learn more_\\u2060(opens in a new window)](https://help.openai.com/en/articles/9793128)\\n\\n*   $200/ month\\n\\n[Get Pro(opens in a new window)](https://chatgpt.com/#pricing)\\n\\nTeam [...] *   $25 per user / month billed annually\\n*   $30 per user / month billed monthly\\n\\n[Try now(opens in a new window)](https://chatgpt.com/?promo_campaign=team1dollar&utm_campaign=WEB-team_try_for_1&utm_internal_medium=referral&utm_internal_source=openai_pricing#team-pricing)\\n\\nEnterprise\\n\\nEnterprise-grade AI, security, and support at scale\\n\\n*   Everything in Team with an expanded context window in GPT‑4o that supports longer inputs and larger files', 'score': 0.72629017}, {'title': 'Is ChatGPT Plus really worth $20 when the free version offers so ...', 'url': 'https://www.zdnet.com/article/is-chatgpt-plus-really-worth-20-when-the-free-version-offers-so-many-premium-features/', 'content': '| Plan | Monthly price | What you get... |\\n| --- | --- | --- |\\n| **Free** | $0 | Basic access to ChatGPT features with daily usage limits. |\\n| **Plus** | $20 | Everything in Free, plus extended limits on messaging, file uploads, data analysis, Advanced Voice Mode, and GPT-4o image generation. Also included is the Codex AI coding agent and the opportunity to test new features. | [...] | **Pro** | $200 | Everything in Plus, with _unlimited_ access to the reasoning models, GPT-4o, and Advanced Voice Mode. Access to o1 pro mode (the most powerful o1 model). Extended access to Sora video generation. Access to Operator research preview (US only). |', 'score': 0.66569364}, {'title': 'ChatGPT Team - OpenAI', 'url': 'https://openai.com/chatgpt/team/', 'content': 'Missing: reviews 2023\"', 'score': 0.6396691}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have gathered sufficient information about OpenAI's ChatGPT Team offerings. Now, I will search for details regarding Anthropic's Claude Pro to complete the comparison.\n",
      "\n",
      "Action: TavilySafeSearch  \n",
      "Action Input: \"Anthropic Claude Pro features pricing reviews 2023\"  \n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m[{'title': 'Review: Should You Spend $20 per Month for the Claude Pro AI ...', 'url': 'https://decrypt.co/155361/review-should-you-spend-20-per-month-for-the-claude-pro-ai-chatbot', 'content': '\"If your conversations are relatively short (approximately 200 English sentences, assuming your sentences are around 15-20 words), you can expect to send at least 100 messages every 8 hours, often more depending on Claude’s current capacity,\" says Anthropic in the [official documentation](https://support.anthropic.com/en/articles/8324991-about-claude-pro-usage) of Claude Pro. \"Over two thirds of all conversations on claude.ai (as of September 2023) have been within this length.\" [...] Anthropic’s [new Claude Pro](https://decrypt.co/155331/anthropic-debuts-claude-pro-rival-to-chatgpt-ai-chatbot) is only available in the US and UK, costing $20 (US) and £18 (UK), putting the AI chatbot in direct competition with OpenAI\\'s ChatGPT Plus service which is more widely available for the same price. [...] ![Jose Antonio Lanz](https://img.decrypt.co/insecure/rs:fit:3840:0:0:0/plain/https://cdn.decrypt.co/wp-content/uploads/2019/04/1623562_10152885173200953_4618803150993506280_n-300x300.jpg@webp)\\n![](https://img.decrypt.co/insecure/rs:fit:3840:0:0:0/plain/https://cdn.decrypt.co/wp-content/uploads/2023/09/anthropic-claude-logo-on-smartphone-ai-chatbot-gID_7.jpg@webp)\\n\\n#### Decrypt’s Art, Fashion, and Entertainment Hub.', 'score': 0.7795405}, {'title': \"Claude AI Review: Testing Anthropic's Assistant - Geekflare\", 'url': 'https://geekflare.com/ai/claude-ai-review/', 'content': '| AI Chatbot | Founded Year | Users (approx.) | API Availability | Internet Access | Image Generation | Free Plan | Starting Pricing |\\n| --- | --- | --- | --- | --- | --- | --- | --- |\\n| **Claude AI** | 2023 | Not disclosed | ✅ | ✅ (paid users) | ❌ | ✅ | Free, Pro at $17/month |\\n| **ChatGPT** | 2022 | 400M weekly active users | ✅ | ✅ (Plus & above) | ✅ (via DALL·E) | ✅ | Free, Plus at $20/month | [...] | **Max****(Team & Enterprise)** | Starts at $100/month/person | 1. Everything in Pro 2. 5x or 20x higher usage 3. Higher output limits 4. Terminal access to Claude Code 5. Research tools 6. API & integrations 7. Priority access & early feature access | Tech teams, enterprises, and developers with intensive use cases | [...] | **Pro** | $20/month (or $17/month, billed annually) | 1. Everything in Free 2. Unlimited projects 3. Web search access 4. Extended reasoning 5. Google Workspace integration 6. Access to more Claude models | Professionals needing enhanced productivity tools |', 'score': 0.7663815}, {'title': \"Anthropic's Claude: What You Need to Know About This AI Tool\", 'url': 'https://www.cnet.com/tech/services-and-software/anthropics-claude-what-you-need-to-know-about-this-ai-tool/', 'content': 'Anthropic offers a variety of pricing plans. There is a free option if you want to test Claude without commitment. For those seeking enhanced capabilities for individual users, the Claude Pro subscription is available at $20 per month. It provides enhanced usage limits and priority access to new features. The Max plan offers everything in Pro for $100 per month, plus additional features like more usage, higher limits and priority access during peak hours.', 'score': 0.7570233}, {'title': \"Claude Pro's two new features make this AI subscription even more ...\", 'url': 'https://www.zdnet.com/article/claude-pros-two-new-features-make-this-ai-subscription-even-more-enticing/', 'content': 'On Tuesday, Anthropic announced that the Claude Pro plan was making two of its most powerful features -- Research and Integrations -- available to Claude Pro subscribers. These features were originally limited to the more expensive Max, Team, and Enterprise plans, and will now be included in the Pro $20 per month mid-tier subscription.', 'score': 0.6729558}]\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have gathered sufficient information about both OpenAI's ChatGPT Team and Anthropic's Claude Pro. Now, I will compile the details into a comparison table, including key features, pricing, and reviews.\n",
      "\n",
      "### Comparison Table: OpenAI's ChatGPT Team vs. Anthropic's Claude Pro\n",
      "\n",
      "| Feature/Aspect                | OpenAI's ChatGPT Team                          | Anthropic's Claude Pro                          |\n",
      "|-------------------------------|------------------------------------------------|-------------------------------------------------|\n",
      "| **Pricing**                   | $25/month per user (billed annually) or $30/month (billed monthly) | $20/month (or $17/month if billed annually)    |\n",
      "| **Key Features**              | - Access to GPT-4 with 32K context window<br>- Tools like DALL·E 3, Vision, Browsing, Advanced Data Analysis<br>- Secure workspace for teams<br>- Admin console for management<br>- Early access to new features | - Unlimited projects<br>- Web search access<br>- Extended reasoning<br>- Google Workspace integration<br>- Access to more Claude models<br>- Research and Integrations features included |\n",
      "| **User Base**                 | 400M weekly active users                       | Not disclosed                                   |\n",
      "| **API Availability**          | Yes                                            | Yes (for paid users)                           |\n",
      "| **Image Generation**          | Yes (via DALL·E)                              | No                                              |\n",
      "| **Free Plan**                 | No                                             | Yes                                            |\n",
      "| **Reviews**                   | Generally positive; praised for performance and features | Positive; noted for competitive pricing and features |\n",
      "| **Additional Plans**          | Enterprise plans available with expanded features | Max plan at $100/month with higher usage limits |\n",
      "\n",
      "### Key Features Breakdown\n",
      "\n",
      "#### OpenAI's ChatGPT Team\n",
      "- **Access to GPT-4**: The latest model with advanced capabilities.\n",
      "- **Team Features**: Shared workspaces, admin console, and secure data handling.\n",
      "- **Tools**: Includes DALL·E 3 for image generation, browsing capabilities, and advanced data analysis.\n",
      "- **Pricing**: $25/month per user (annual) or $30/month (monthly).\n",
      "\n",
      "#### Anthropic's Claude Pro\n",
      "- **Enhanced Usage**: Unlimited projects and web search access.\n",
      "- **Integrations**: Google Workspace integration and access to more Claude models.\n",
      "- **Research Features**: Recently added research and integrations features to the Pro plan.\n",
      "- **Pricing**: $20/month (or $17/month if billed annually).\n",
      "\n",
      "### Conclusion\n",
      "Both OpenAI's ChatGPT Team and Anthropic's Claude Pro offer competitive features and pricing. ChatGPT Team is more focused on team collaboration and advanced tools, while Claude Pro provides a strong individual user experience with a lower price point and essential integrations.\n",
      "\n",
      "Final Answer: The comparison table and details above provide a clear overview of the offerings from OpenAI's ChatGPT Team and Anthropic's Claude Pro, including features, pricing, and reviews.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Your prompt here\n",
    "prompt_3 = \"\"\"\n",
    "Compare the offerings provided by OpenAI's ChatGPT Team and Anthropic's Claude Pro in 2025.\n",
    "\n",
    "- Provide a comparison table.\n",
    "- List key features, pricing and reviews.\n",
    "- Structure the response in clear Markdown.\n",
    "\"\"\"\n",
    "\n",
    "# Run it\n",
    "response_3 = agent.run(prompt_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8bf9711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The comparison table and details above provide a clear overview of the offerings from OpenAI's ChatGPT Team and Anthropic's Claude Pro, including features, pricing, and reviews."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(response_3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c47c22",
   "metadata": {},
   "source": [
    "Not sure why the table isn't properly displayed by the `display` function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f40dbe3",
   "metadata": {},
   "source": [
    "## Bonus Task: Propose and Implement Your Own Use Case\n",
    "\n",
    "As a final challenge, think of a real-world scenario where an AI agent could provide value using web search or external tools.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3e945b",
   "metadata": {},
   "source": [
    "See extra file: [LangGraph_Hoehnbot.ipynb](LangGraph_Hoehnbot.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp.venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
